# PolyPaper - A Scientific Research Publication Platform

## Overview

PolyPaper is a web platform designed to centralize and showcase the paper publications of scientific researchers affiliated with a Listic research center. The platform employs Next.js for the frontend, utilizing 3D modelization to represent researchers, nodes, and their publications. Each publication is transformed into a non-fungible token (NFT), and a unique address is assigned to each professor. Notably, professors receive royalties whenever their publications are traded.

## Features

- **Next.js Frontend:** PolyPaper utilizes Next.js to create a seamless and efficient user interface for exploring scientific publications.
- **3D Modelization:** The platform incorporates 3D modelization to visually represent researchers, nodes, and the connections between publications, enhancing the overall user experience.
- **NFT Transformation:** Every publication is transformed into a non-fungible token (NFT), ensuring uniqueness and traceability on the blockchain.
- **Professor Addresses:** Each professor is assigned a unique address, facilitating ownership tracking and royalty distribution for their publications.
- **Royalty System:** Professors receive royalties whenever their publications are traded, creating a fair compensation model for their academic contributions.
- **Next.js and Node.js:** The combination of Next.js for the frontend and Node.js for the backend ensures a robust and scalable architecture.
- **MongoDB Database:** PolyPaper utilizes MongoDB as the backend database, providing a flexible and scalable solution for storing and retrieving data.

## Data Sources and Scraping

PolyPaper aggregates publications from various scientific paper platforms, including but not limited to Google Scholar, Sci-Hub, and ScienceOpen. The data scraping process involved extracting information from these platforms, ensuring a comprehensive collection of scientific publications for a diverse range of research articles.

### Data Scraping Process

The data scraping process involved the following steps:

1. **Identification of Platforms:** Identify and select reputable scientific paper platforms, such as Google Scholar, Sci-Hub, and ScienceOpen, for data extraction.

2. **Web Scraping:** Utilize web scraping techniques to extract relevant information from each platform, including publication titles, authors, abstracts, and other metadata.

3. **Data Transformation:** Transform the scraped data into a structured format suitable for storage and presentation on PolyPaper.

4. **Quality Assurance:** Implement quality assurance measures to validate the accuracy and completeness of the scraped data.

5. **Regular Updates:** Establish a process for regular updates to ensure that PolyPaper reflects the most recent and relevant scientific publications from multiple platforms.

## License

PolyPaper is licensed under the MIT License. Feel free to use, modify, and distribute the code for your purposes.
